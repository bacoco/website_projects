{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Introduction to Deep Learning with Keras datacamp.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMsnYceqFz+4ln8VdOpbQm3",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/bacoco/website_projects/blob/master/Introduction_to_Deep_Learning_with_Keras_datacamp.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5a16Mr71FYSD"
      },
      "source": [
        "#Introduction to Deep Learning with Keras datacamp"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EQA3PHNQ-owP",
        "outputId": "b6aa038d-0df5-4ece-8845-b36b1789af2d"
      },
      "source": [
        "# Import the Sequential model and Dense layer\r\n",
        "from keras.models import Sequential\r\n",
        "from keras.layers import Dense\r\n",
        "\r\n",
        "# Create a Sequential model\r\n",
        "model = Sequential()\r\n",
        "\r\n",
        "# Add an input layer and a hidden layer with 10 neurons\r\n",
        "model.add(Dense(10, input_shape=(2,), activation=\"relu\"))\r\n",
        "\r\n",
        "# Add a 1-neuron output layer\r\n",
        "model.add(Dense(1))\r\n",
        "\r\n",
        "# Summarise your model\r\n",
        "model.summary()"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense (Dense)                (None, 10)                30        \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 1)                 11        \n",
            "=================================================================\n",
            "Total params: 41\n",
            "Trainable params: 41\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ME5UT_yb_04j",
        "outputId": "bdf8b872-53ca-4b08-e4e2-259361a069b6"
      },
      "source": [
        "# Instantiate a new Sequential model\r\n",
        "model = Sequential()\r\n",
        "\r\n",
        "# Add a Dense layer with five neurons and three inputs\r\n",
        "model.add(Dense(5, input_shape=(3,), activation=\"relu\"))\r\n",
        "\r\n",
        "# Add a final Dense layer with one neuron and no activation\r\n",
        "model.add(Dense(1,activation=None))\r\n",
        "\r\n",
        "# Summarize your model\r\n",
        "model.summary()"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_2 (Dense)              (None, 5)                 20        \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 1)                 6         \n",
            "=================================================================\n",
            "Total params: 26\n",
            "Trainable params: 26\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MffoXUEfBGCJ"
      },
      "source": [
        "#A multi-class model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J9BR3OPtBgUM"
      },
      "source": [
        "# Transform into a categorical variable\r\n",
        "darts.competitor = pd.Categorical(darts.competitor)\r\n",
        "\r\n",
        "# Assign a number to each category (label encoding)\r\n",
        "darts.competitor = darts.competitor.cat.codes \r\n",
        "\r\n",
        "# Import to_categorical from keras utils module\r\n",
        "from keras.utils import to_categorical\r\n",
        "\r\n",
        "coordinates = darts.drop(['competitor'], axis=1)\r\n",
        "# Use to_categorical on your labels\r\n",
        "competitors = to_categorical(darts.competitor)\r\n",
        "\r\n",
        "# Now print the one-hot encoded labels\r\n",
        "print('One-hot encoded competitors: \\n',competitors)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fgZLDsZPBG0L"
      },
      "source": [
        "# Instantiate a sequential model\r\n",
        "model = Sequential()\r\n",
        "  \r\n",
        "# Add 3 dense layers of 128, 64 and 32 neurons each\r\n",
        "model.add(Dense(128, input_shape=(2,), activation='relu'))\r\n",
        "model.add(Dense(64, activation='relu'))\r\n",
        "model.add(Dense(32, activation='relu'))\r\n",
        "  \r\n",
        "# Add a dense layer with as many neurons as competitors\r\n",
        "model.add(Dense(4, activation='softmax'))\r\n",
        "  \r\n",
        "# Compile your model using categorical_crossentropy loss\r\n",
        "model.compile(loss='categorical_crossentropy',\r\n",
        "              optimizer='adam',\r\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CZ-s2GFVGeob"
      },
      "source": [
        "# Predict on coords_small_test\r\n",
        "preds = model.predict(coords_small_test)\r\n",
        "\r\n",
        "# Print preds vs true values\r\n",
        "print(\"{:45} | {}\".format('Raw Model Predictions','True labels'))\r\n",
        "for i,pred in enumerate(preds):\r\n",
        "  print(\"{} | {}\".format(pred,competitors_small_test[i]))\r\n",
        "\r\n",
        "# Extract the position of highest probability from each pred vector\r\n",
        "preds_chosen = [np.argmax(pred) for pred in preds]\r\n",
        "\r\n",
        "# Print preds vs true values\r\n",
        "print(\"{:10} | {}\".format('Rounded Model Predictions','True labels'))\r\n",
        "for i,pred in enumerate(preds_chosen):\r\n",
        "  print(\"{:25} | {}\".format(pred,competitors_small_test[i]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MTlsVABuBs4i"
      },
      "source": [
        "#Multi-label classification"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RcF6SLM_B484"
      },
      "source": [
        "# Instantiate a Sequential model\r\n",
        "model = Sequential()\r\n",
        "\r\n",
        "# Add a hidden layer of 64 neurons and a 20 neuron's input\r\n",
        "model.add(Dense(64,input_shape=(20,),activation='relu'))\r\n",
        "\r\n",
        "# Add an output layer of 3 neurons with sigmoid activation\r\n",
        "model.add(Dense(3,activation='sigmoid'))\r\n",
        "\r\n",
        "# Compile your model with binary crossentropy loss\r\n",
        "model.compile(optimizer='adam',\r\n",
        "           loss = 'binary_crossentropy',\r\n",
        "           metrics=['accuracy'])\r\n",
        "\r\n",
        "model.summary()\r\n",
        "\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QnZa6rOKCETQ"
      },
      "source": [
        "# Train for 100 epochs using a validation split of 0.2\r\n",
        "model.fit(sensors_train, parcels_train, epochs = 100, validation_split = 0.2)\r\n",
        "\r\n",
        "# Predict on sensors_test and round up the predictions\r\n",
        "preds = model.predict(sensors_test)\r\n",
        "preds_rounded = np.round(preds)\r\n",
        "\r\n",
        "# Print rounded preds\r\n",
        "print('Rounded Predictions: \\n', preds_rounded)\r\n",
        "\r\n",
        "# Evaluate your model's accuracy on the test data\r\n",
        "accuracy = model.evaluate(sensors_test, parcels_test)[1]\r\n",
        "\r\n",
        "# Print accuracy\r\n",
        "print('Accuracy:', accuracy)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v2p86SsgCji1"
      },
      "source": [
        "#CALLBACKS"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rsbcMxLACS4r"
      },
      "source": [
        "###The history callback"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ezgbmrx0CXeF"
      },
      "source": [
        "# Train your model and save its history\r\n",
        "h_callback = model.fit(X_train, y_train, epochs = 50,\r\n",
        "               validation_data=(X_test, y_test))\r\n",
        "\r\n",
        "# Plot train vs test loss during training\r\n",
        "plot_loss(h_callback.history['loss'], h_callback.history['val_loss'])\r\n",
        "\r\n",
        "# Plot train vs test accuracy during training\r\n",
        "plot_accuracy(h_callback.history['acc'], h_callback.history['val_acc'])\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KxgSFNovCrrq"
      },
      "source": [
        "###Early stopping your model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "COlyioqyCwmz"
      },
      "source": [
        "# Import the early stopping callback\r\n",
        "from keras.callbacks import EarlyStopping\r\n",
        "\r\n",
        "# Define a callback to monitor val_acc\r\n",
        "monitor_val_acc = EarlyStopping(monitor='val_acc', \r\n",
        "                       patience=5)\r\n",
        "\r\n",
        "# Train your model using the early stopping callback\r\n",
        "model.fit(X_train, y_train, \r\n",
        "           epochs=1000, validation_data=(X_test,y_test),\r\n",
        "           callbacks= [monitor_val_acc])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HXTAEp_rC0BB"
      },
      "source": [
        "###A combination of callbacks"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l5zlzgFKC4wp"
      },
      "source": [
        "# Import the EarlyStopping and ModelCheckpoint callbacks\r\n",
        "from keras.callbacks import EarlyStopping, ModelCheckpoint\r\n",
        "\r\n",
        "# Early stop on validation accuracy\r\n",
        "monitor_val_acc = EarlyStopping(monitor = 'val_acc', patience = 3)\r\n",
        "\r\n",
        "# Save the best model as best_banknote_model.hdf5\r\n",
        "modelCheckpoint = ModelCheckpoint('best_banknote_model.hdf5', save_best_only = True)\r\n",
        "\r\n",
        "# Fit your model for a stupid amount of epochs\r\n",
        "h_callback = model.fit(X_train, y_train,\r\n",
        "                    epochs = 1000000000000,\r\n",
        "                    callbacks = [monitor_val_acc, modelCheckpoint],\r\n",
        "                    validation_data = (X_test, y_test))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_S7DWG1GDIRp"
      },
      "source": [
        "### EXO : Learning the digits"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zrdzx8L0DK0x"
      },
      "source": [
        "# Instantiate a Sequential model\r\n",
        "model = Sequential()\r\n",
        "\r\n",
        "# Input and hidden layer with input_shape, 16 neurons, and relu \r\n",
        "model.add(Dense(16, input_shape = (64,), activation = 'relu'))\r\n",
        "\r\n",
        "# Output layer with 10 neurons (one per digit) and softmax\r\n",
        "model.add(Dense(10,activation='softmax'))\r\n",
        "\r\n",
        "# Compile your model\r\n",
        "model.compile(optimizer = 'adam', loss = 'categorical_crossentropy', metrics = ['accuracy'])\r\n",
        "\r\n",
        "# Test if your model is well assembled by predicting before training\r\n",
        "print(model.predict(X_train))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qTiLc94kDk5c"
      },
      "source": [
        "#### Overfiting ?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kQHieWLkDfku"
      },
      "source": [
        "# Train your model for 60 epochs, using X_test and y_test as validation data\r\n",
        "h_callback = model.fit(X_train, y_train, epochs = 60, validation_data = (X_test, y_test), verbose=0)\r\n",
        "\r\n",
        "# Extract from the h_callback object loss and val_loss to plot the learning curve\r\n",
        "plot_loss(h_callback.history['loss'], h_callback.history['val_loss'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5ykAZzp2DqZ9"
      },
      "source": [
        "####Do we need more data?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yyGzfhXsDt50"
      },
      "source": [
        "for size in training_sizes:\r\n",
        "  \t# Get a fraction of training data (we only care about the training data)\r\n",
        "    X_train_frac, y_train_frac = X_train[:size], y_train[:size]\r\n",
        "\r\n",
        "    # Reset the model to the initial weights and train it on the new training data fraction\r\n",
        "    model.set_weights(initial_weights)\r\n",
        "    model.fit(X_train_frac, y_train_frac, epochs = 50, callbacks = [early_stop])\r\n",
        "\r\n",
        "    # Evaluate and store both: the training data fraction and the complete test set results\r\n",
        "    train_accs.append(model.evaluate(X_train_frac, y_train_frac)[1])\r\n",
        "    test_accs.append(model.evaluate(X_test, y_test)[1])\r\n",
        "    \r\n",
        "# Plot train vs test accuracies\r\n",
        "plot_results(train_accs, test_accs)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "97ar8nSxD77H"
      },
      "source": [
        "# Different activation functions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OH2-03NtEJ46"
      },
      "source": [
        "####Comparing activation functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sc4HmbUfEAqH"
      },
      "source": [
        "# Activation functions to try\r\n",
        "activations = ['relu', 'leaky_relu', 'sigmoid', 'tanh']\r\n",
        "\r\n",
        "# Loop over the activation functions\r\n",
        "activation_results = {}\r\n",
        "\r\n",
        "for act in activations:\r\n",
        "  # Get a new model with the current activation\r\n",
        "  model = get_model(act)\r\n",
        "  # Fit the model and store the history results\r\n",
        "  h_callback = model.fit(X_train,y_train,epochs=20,verbose=0,validation_data=(X_test,y_test))\r\n",
        "  activation_results[act] = h_callback"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BSZJ3tDJEVjY"
      },
      "source": [
        "# Create a dataframe from val_loss_per_function\r\n",
        "val_loss= pd.DataFrame(val_loss_per_function)\r\n",
        "\r\n",
        "# Call plot on the dataframe\r\n",
        "val_loss.plot()\r\n",
        "plt.show()\r\n",
        "\r\n",
        "# Create a dataframe from val_acc_per_function\r\n",
        "val_acc = pd.DataFrame(val_acc_per_function)\r\n",
        "\r\n",
        "# Call plot on the dataframe\r\n",
        "val_acc.plot()\r\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w6RNGoRpEabG"
      },
      "source": [
        "##Batch size and batch normalization\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e9SRlxGoEkfx"
      },
      "source": [
        "# Import batch normalization from keras layers\r\n",
        "from keras.layers import BatchNormalization\r\n",
        "\r\n",
        "# Build your deep network\r\n",
        "batchnorm_model = Sequential()\r\n",
        "batchnorm_model.add(Dense(50, input_shape=(64,), activation='relu', kernel_initializer='normal'))\r\n",
        "batchnorm_model.add(BatchNormalization())\r\n",
        "batchnorm_model.add(Dense(50, activation='relu', kernel_initializer='normal'))\r\n",
        "batchnorm_model.add(BatchNormalization())\r\n",
        "batchnorm_model.add(Dense(50, activation='relu', kernel_initializer='normal'))\r\n",
        "batchnorm_model.add(BatchNormalization())\r\n",
        "batchnorm_model.add(Dense(10, activation='softmax', kernel_initializer='normal'))\r\n",
        "\r\n",
        "# Compile your model with sgd\r\n",
        "batchnorm_model.compile(optimizer='sgd', loss='categorical_crossentropy', metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o4ax_wN0ESIO"
      },
      "source": [
        "##Hyperparameter tuning\r\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "brhqhuWFEz64"
      },
      "source": [
        "####Preparing a model for tuning"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c1Ppe4VUEudU"
      },
      "source": [
        "# Creates a model given an activation and learning rate\r\n",
        "def create_model(learning_rate, activation):\r\n",
        "  \r\n",
        "  \t# Create an Adam optimizer with the given learning rate\r\n",
        "  \topt = Adam(lr = learning_rate)\r\n",
        "  \t\r\n",
        "  \t# Create your binary classification model  \r\n",
        "  \tmodel = Sequential()\r\n",
        "  \tmodel.add(Dense(128, input_shape = (30,), activation = activation))\r\n",
        "  \tmodel.add(Dense(256, activation = activation))\r\n",
        "  \tmodel.add(Dense(1, activation = 'sigmoid'))\r\n",
        "  \t\r\n",
        "  \t# Compile your model with your optimizer, loss, and metrics\r\n",
        "  \tmodel.compile(optimizer = opt, loss = 'binary_crossentropy', metrics = ['accuracy'])\r\n",
        "  \treturn model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pc8olk95E8U_"
      },
      "source": [
        "####Tuning the model parameters scikit_learn"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3vgEzuV7E9TC"
      },
      "source": [
        "# Import KerasClassifier from keras scikit learn wrappers\r\n",
        "from keras.wrappers.scikit_learn import KerasClassifier\r\n",
        "\r\n",
        "# Create a KerasClassifier\r\n",
        "model = KerasClassifier(build_fn = create_model)\r\n",
        "\r\n",
        "# Define the parameters to try out\r\n",
        "params = {'activation': ['relu', 'tanh'], 'batch_size': [32, 128, 256], \r\n",
        "          'epochs': [50, 100, 200], 'learning_rate': [0.1, 0.01, 0.001]}\r\n",
        "\r\n",
        "# Create a randomize search cv object passing in the parameters to try\r\n",
        "random_search = RandomizedSearchCV(model, param_distributions = params, cv = KFold(3))\r\n",
        "\r\n",
        "# Running random_search.fit(X,y) would start the search,but it takes too long! \r\n",
        "show_results()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7v4ufhGgFFX0"
      },
      "source": [
        "####Training with cross-validation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ALzKKlL5FGPh"
      },
      "source": [
        "# Import KerasClassifier from keras wrappers\r\n",
        "from keras.wrappers.scikit_learn import KerasClassifier\r\n",
        "\r\n",
        "# Create a KerasClassifier\r\n",
        "model = KerasClassifier(build_fn = create_model(learning_rate = 0.001, activation = 'relu'), epochs = 50, \r\n",
        "             batch_size = 128, verbose = 0)\r\n",
        "\r\n",
        "# Calculate the accuracy score for each fold\r\n",
        "kfolds = cross_val_score(model, X, y, cv = 3)\r\n",
        "\r\n",
        "# Print the mean accuracy\r\n",
        "print('The mean accuracy was:', kfolds.mean())\r\n",
        "\r\n",
        "# Print the accuracy standard deviation\r\n",
        "print('With a standard deviation of:', kfolds.std())"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}